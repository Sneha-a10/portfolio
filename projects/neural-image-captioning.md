# Neural Image Captioning Pipeline

## Problem
Understanding and indexing image content is difficult without descriptive metadata, limiting accessibility and automation for visually impaired users and search systems.

## What I Built
An end-to-end image captioning pipeline involving image and text preprocessing, tokenizer design, DenseNet201-based feature extraction, and an LSTM sequence generation model, with performance evaluated using BLEU scores.

## How It Works
The pipeline preprocesses images and text, extracts features using DenseNet201, and generates captions using an LSTM model. The system is trained on image-caption pairs and evaluated for caption quality.

## Tech Stack
- TensorFlow/Keras
- Pandas
- NumPy
- NLTK
- Matplotlib

## Links
- GitHub: https://github.com/Sneha-a10/Image_captioning
- Demo:
